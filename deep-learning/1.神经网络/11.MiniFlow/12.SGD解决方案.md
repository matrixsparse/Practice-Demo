# SGD 解决方案

```bash
def sgd_update(trainables, learning_rate=1e-2):
    """
    Updates the value of each trainable with SGD.

    Arguments:

        `trainables`: A list of `Input` nodes representing weights/biases.
        `learning_rate`: The learning rate.
    """
    # Performs SGD
    #
    # Loop over the trainables
    for t in trainables:
        # Change the trainable's value by subtracting the learning rate
        # multiplied by the partial of the cost with respect to this
        # trainable.
        partial = t.gradients[t]
        t.value -= learning_rate * partial
```

来看下最后几行：

```bash
# Performs SGD
#
# Loop over the trainables
for t in trainables:
    # Change the trainable's value by subtracting the learning rate
    # multiplied by the partial of the cost with respect to this
    # trainable.
    partial = t.gradients[t]
    t.value -= learning_rate * partial
```

有两个关键步骤。第一步，Cost (C) 关于 trainable t 的偏导 可以如下得到

```bash
partial = t.gradients[t]
```

第二步，trainable 的值根据等式 (12) 进行更新

```bash
t.value -= learning_rate * partial
```

对所有 trainable 执行

![All text](http://ww1.sinaimg.cn/large/dc05ba18ly1fnt05wtlh1j20eb022dfn.jpg)
