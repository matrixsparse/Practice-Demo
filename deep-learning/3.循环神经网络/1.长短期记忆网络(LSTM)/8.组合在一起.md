# 组合在一起

正如我们之前看到的，这就是LSTM的结果，里面有四个门，这就是遗忘门

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fofapy1kyij21tk0seq9l.jpg)

会接受长期记忆并遗忘掉一部分，学习门会把短期记忆和事件放到一起，作为我们最近学到的信息，记忆门则把还没有遗忘的长期记忆和刚学到的新信息放到一起，以便更新长期记忆并将其输出，最后使用门也会把我们刚学到的信息和还没遗忘的长期记忆放到一起，从而作出预测并更新短期记忆，这就是把所有东西放到一起的样子，并不复杂，对嘛？你可能会在想太复杂了对嘛，为什么有时候要用tanh有时候却要用sigmoid？为什么有时候要相乘，还有时候又要相加？有时候又要用更复杂的线性函数？你可能会想到别的结构，一些更合理或更简单的结构
