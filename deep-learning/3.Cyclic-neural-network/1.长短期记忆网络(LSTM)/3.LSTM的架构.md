# LSTM 的架构

RNN的架构，基本上我们需要拿事件Et和记忆Mt-1

它们来自上一个时间点，把它们代入一个简单的tanh或sigmoid激活函数里，从而得到输出和记忆Mt

更具体地讲，我们要把这两个向量加到一起，让它们乘以一个矩阵W再加一个偏差b，然后把整个公式套到tanh函数里，从而得到输出Mt，这个输出是一个预测，也是我们要输入下一个节点的记忆

LSTM的结构很类似，但里面有更多节点，还有两个输入和输出，因为它要跟踪长期记忆和短期记忆，正如我之前所说的短期记忆，就是输出或预测结果
