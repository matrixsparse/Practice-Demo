# 代价

你可能觉得奇怪，为何 _sigmoid 具有单独的方法。正如在 S 型函数（等式 (4)）的导数中看到的，S 型函数实际上是它自己的导数的一部分

将 _sigmoid 分离出来意味着你不需要为前向传播和反向传播实现两次

这很不错！此时，你已经使用了权重和偏置来计算输出。并且你使用了激活函数来对输出进行分类

你可能还记得，神经网络通过修改权重和偏置（根据标签化的数据集进行训练）改善输出的精确度

我们可以采用多种技巧来定义神经网络的精确度，所有技巧围绕的都是神经网络是否能够生成与已知正确的值非常接近的值

人们用不同的名称来表示这一精确度测量者，通常称之为损失或代价
