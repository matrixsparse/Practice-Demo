# 梯度下降

注意，我们的目标是通过尽量减小代价，使我们的网络输出与目标值尽量接近。你可以将代价看做一座山，我们想要到达山底

想象你的模型参数表示为一个停在山顶的球。直观地来说，我们希望将球推下山。这样可以明白，但是我们讨论的是代价函数，如何知道哪条路是下山呢？

幸运的是，梯度下降正好给出了这一信息。

严格来说，梯度实际上指的是上坡，是最陡上升方向。但是，如果我们在此值前面加个负号，就得出了最陡下降方向，这正是我们需要的。

暂时可以将坡度看做数字向量。每个数字表示我们应该对照着调整神经网络中相应的权重或偏置的数量。按照梯度值调整所有的权重和偏置降低了网络的代价（或误差）。

好的！现在我们知道朝着哪个方向推球了。下一步是考虑用多大的推力，称之为学习速度，该名称比较恰当，因为该值确定了神经网络学习的快慢速度。

你可能希望设置非常大的学习速度，这一网络就能学的非常快，对吧？

要小心！如果该值太大，可能会迭代过度并最终偏离目标。呀！

![All text](http://ww1.sinaimg.cn/large/dc05ba18ly1fnstlaxv8wj209q061q2w.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18ly1fnstlay4uyj20au06rwei.jpg)

>什么样的学习速度合适？

只能做出猜测，根据以往经验，0.1 至 0.0001 范围的值效果最好

0.001 至 0.0001 范围的值很常见，因为 0.1 和 0.01 有时候过大

下面是梯度下降的公式（伪代码）：

```bash
x = x - learning_rate * gradient_of_x
```

* `x` ：神经网络使用的参数（即`单个权重或偏置`）
* `gradient_of_x`：上坡方向
* `learning_rate`：推力

将 `gradient_of_x（上坡方向）`与 `learning_rate（推力）相乘`，用 x 减去相乘结果，从而向下推动

>gd.py

```bash
#!/usr/bin/env python
# -*- coding:utf-8 -*-
# @Copyright (C), 2018, matrix

def gradient_descent_update(x, gradx, learning_rate):
    """
    Performs a gradient descent update.
    """
    # TODO: Implement gradient descent.
    x = x - learning_rate * gradx

    # Return the new value for x
    return x
```

>f.py

```bash
#!/usr/bin/env python
# -*- coding:utf-8 -*-
# @Copyright (C), 2018, matrix

"""
Given the starting point of any `x` gradient descent
should be able to find the minimum value of x for the
cost function `f` defined below.
"""
import random
from gd import gradient_descent_update


def f(x):
    """
    Quadratic function.

    It's easy to see the minimum value of the function
    is 5 when is x=0.
    """
    return x ** 2 + 5


def df(x):
    """
    Derivative of `f` with respect to `x`.
    """
    return 2 * x


# Random number between 0 and 10,000. Feel free to set x whatever you like.
x = random.randint(0, 10000)
# TODO: Set the learning rate
learning_rate = 0.5
epochs = 100

for i in range(epochs + 1):
    cost = f(x)
    gradx = df(x)
    print("EPOCH {}: Cost = {:.3f}, x = {:.3f}".format(i, cost, gradx))
    x = gradient_descent_update(x, gradx, learning_rate)
```
