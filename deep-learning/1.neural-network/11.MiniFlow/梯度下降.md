# 梯度下降

注意，我们的目标是通过尽量减小代价，使我们的网络输出与目标值尽量接近。你可以将代价看做一座山，我们想要到达山底

想象你的模型参数表示为一个停在山顶的球。直观地来说，我们希望将球推下山。这样可以明白，但是我们讨论的是代价函数，如何知道哪条路是下山呢？

幸运的是，梯度下降正好给出了这一信息。

严格来说，梯度实际上指的是上坡，是最陡上升方向。但是，如果我们在此值前面加个负号，就得出了最陡下降方向，这正是我们需要的。

暂时可以将坡度看做数字向量。每个数字表示我们应该对照着调整神经网络中相应的权重或偏置的数量。按照梯度值调整所有的权重和偏置降低了网络的代价（或误差）。

好的！现在我们知道朝着哪个方向推球了。下一步是考虑用多大的推力，称之为学习速度，该名称比较恰当，因为该值确定了神经网络学习的快慢速度。

你可能希望设置非常大的学习速度，这一网络就能学的非常快，对吧？

要小心！如果该值太大，可能会迭代过度并最终偏离目标。呀！

![All text](http://ww1.sinaimg.cn/large/dc05ba18ly1fnstlaxv8wj209q061q2w.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18ly1fnstlay4uyj20au06rwei.jpg)
