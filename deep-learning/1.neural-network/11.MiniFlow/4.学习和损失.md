# 学习和损失

就像当前状态的 MiniFlow 一样，神经网络传入输入并产生输出

但是与当前状态的 MiniFlow 不一样，神经网络可以逐渐改善其输出的准确性（很难想象 Add 会逐渐提高准确性！）

要理解为何准确性很重要，请首先实现一个比 Add 更难（也更实用）的节点

## 线性方程

![All text](http://ww1.sinaimg.cn/large/dc05ba18ly1fnrtg1ostdj20m10c93zd.jpg)

>简单的人工神经元取决于以下三个组件

* 输入， Xi
* 权重， Wi
* 偏置， b
* 输出 y 就是输入加上偏置的加权和

注意，通过更改权重，你可以更改任何给定输入对输出带来的影响

`神经网络的学习流程`发生在`反向传播过程中`

在反向传播中，网络会修改权重，以改善网络的输出准确性

在下个测验中，你将构建一个线性神经元，该神经元通过应用简化的加权和生成输出

Linear 应该传入长为 n 的传入节点列表、长度为 n 的权重列表和偏置

>nn.py

```bash
"""
NOTE: Here we're using an Input node for more than a scalar.
In the case of weights and inputs the value of the Input node is
actually a python list!

In general, there's no restriction on the values that can be passed to an Input node.
"""
from miniflow import *

inputs, weights, bias = Input(), Input(), Input()

f = Linear(inputs, weights, bias)

feed_dict = {
    inputs: [6, 14, 3],
    weights: [0.5, 0.25, 1.4],
    bias: 2
}

graph = topological_sort(feed_dict)
output = forward_pass(f, graph)

print(output) # should be 12.7 with this example
```

>miniflow.py

```bash
"""
NOTE: Here we're using an Input node for more than a scalar.
In the case of weights and inputs the value of the Input node is
actually a python list!

In general, there's no restriction on the values that can be passed to an Input node.
"""
from miniflow import *

inputs, weights, bias = Input(), Input(), Input()

f = Linear(inputs, weights, bias)

feed_dict = {
    inputs: [6, 14, 3],
    weights: [0.5, 0.25, 1.4],
    bias: 2
}

graph = topological_sort(feed_dict)
output = forward_pass(f, graph)

print(output) # should be 12.7 with this example
```
