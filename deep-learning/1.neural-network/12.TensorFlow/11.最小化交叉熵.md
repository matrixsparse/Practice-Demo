# 最小化交叉熵

我们该如何确定权重项w和偏差值b的值，以使我们的分类器能够完成我们所期望的工作

也就是说，要使之对正确分类距离要足够小，对错误分类的距离足够大

你可以选择通过这样的方式衡量，求出对所有训练集样本和所有类别的距离之和，也就是求出训练罚函数

这个函数，求出了对于所有训练集样本的交叉熵的均值，是一个非常庞大的函数
训练集中的每个样本，都将被乘上这个巨大的W矩阵，并且它们都将被加起来，得到这个巨大的求和，我们希望每一个距离值都很小，也就是说

分类器能够，对训练集中的每个样本都能很好地分类，因此我们希望这个罚函数值很小

罚函数是一个关于权重项w和偏差项b的函数

我们来看看，如何求罚函数最小值

作为演示，考察某罚函数，只有两个自变量

我们记为w1和w2

该函数的值在某些区域很大

在另一些区域很小

我们的目标是去寻找使得罚函数值最小的权重值w

将一个机器学习问题转换为了一个数值优化问题

我们有很多的方法来解决这个数值优化问题

最简单的方法之一，也许你可能遇到过，是梯度下降法

对罚函数的每一个变量求偏导数

并将每个变量值加上该偏导数值

直到你达到全局最小值

特别是你能够帮你高效求出偏导数的数值工具的时候