# TensorFlow Softmax

Softmax 函数可以把它的输入，通常被称为 logits 或者 logit scores，处理成 0 到 1 之间

并且能够把输出归一化到和为 1

这意味着 softmax 函数与分类的概率分布等价

它是一个网络预测多分类问题的最佳输出激活函数

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fnc27z39okj20ye0c2myv.jpg)

当我们用 TensorFlow 来构建一个神经网络时，相应地，它有一个计算 softmax 的函数

```bash
x = tf.nn.softmax([2.0, 1.0, 0.2])
```

就是这么简单，tf.nn.softmax() 直接为你实现了 softmax 函数，它输入 logits，返回 softmax 激活函数。

>quiz.py

```bash
#!/usr/bin/env python
# -*- coding:utf-8 -*-
# @Copyright (C), 2018, matrix

import tensorflow as tf


def run():
    output = None
    logit_data = [2.0, 1.0, 0.1]
    logits = tf.placeholder(tf.float32)

    # TODO: Calculate the softmax of the logits
    softmax = tf.nn.softmax(logits)

    with tf.Session() as sess:
        # TODO: Feed in the logit data
        output = sess.run(softmax, feed_dict={logits: logit_data})

    return output

print(run())
```