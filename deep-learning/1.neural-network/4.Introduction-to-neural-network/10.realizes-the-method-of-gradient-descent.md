# realizes the method of gradient descent

## 如何更新我们的权重

```bash
ΔW​ij=ηδjXi
```

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn3pgsa1w3j20gq016a9u.jpg)

如何实现一次更新，那我们如何把代码转化为能够计算多次权重更新，使得我们的网络能够真正学习呢？
​​
## 案例

```bash
拿一个研究生学院录取数据，用梯度下降训练一个网络

数据有三个输入特征：GRE 分数、GPA 分数和本科院校排名（从 1 到 4）

排名 1 代表最好，排名 4 代表最差
```

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn3pg4j52kj20jj0gyn04.jpg)

### 目标

```bash
基于这些特征来预测一个学生能否被研究生院录取

将使用有一个输出层的网络 , 用 sigmoid 做为激活函数
```

### 数据清理

先做数据转换

rank 是`类别特征`，其中的数字并不表示任何相对的值

排名第 2 并不是排名第 1 的两倍
排名第 3 也不是排名第 2 的 1.5 倍

因此，我们需要用 dummy variables 来对 rank 进行编码

把数据分成 4 个新列，用 0 或 1 表示
排名为 1 的行对应 rank_1 列的值为 1 ，其余三列的值为 0
排名为 2 的行对应 rank_2 列的值为 1 ，其余三列的值为 0

还需要把 GRE 和 GPA 数据标准化，也就是说使得它们的均值为 0，标准偏差为 1 <-- 怎么做？

因为 sigmoid 函数会挤压很大或者很小的输入
很大或者很小输入的梯度为 0，这意味着梯度下降的步长也会是 0

由于 GRE 和 GPA 的值都相当大，我们在初始化权重的时候需要非常小心，否则梯度下降步长将会消失，网络也没法训练了。相对地，如果我们对数据做了标准化处理，就能更容易地对权重进行初始化

这只是一个简单介绍，你之后还会学到如何预处理数据，如果你想了解我是怎么做的，可以查看下面编程练习中的 data_prep.py 文件。

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn3po7puv5j20j80f5410.jpg)

## 实现梯度下降

```bash
实现梯度下降，用录取数据来训练它

训练一个网络直到你达到训练数据的最小的均方差 mean square error(MSE)
```

* 网络的输出：output
* 输出误差：error
* 误差项：error_term
* 权重步长更新：del_w +=
* 权重更新：weights +=


>binary
