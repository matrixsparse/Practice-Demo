# Gradient descent mathematics【梯度下降：数学】

```bash
构建神经网络是为了输出预测结果
但若提前不知道正确权重，应当怎样处理呢
```

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn2r0skr6aj21pc0uudxu.jpg)

```bash
先输入已知的正确数据，根据预测结果来调整权重参数，首先我们需要选取衡量预测误差的标准

最容易想到的是，用实际目标值y减去网络输出值y^以两者差值衡量误差，若预测值高于目标值，差值为负数，若预测值低于目标值，差值为正数
```

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn32d0mrtlj210i08a75i.jpg)

```bash
希望误差能够保持符号一致
要让符号全部归正，可以求差值的平方
```

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn32fyauywj210w09cabv.jpg)

```bash
你可以在想，为什么不直接用绝对值呢
使用平方值，异常值会被赋予更高的惩罚值
而较小误差的惩罚值则较低
而且使用平方值还能简化后续计算
但目前我们进的到单次预测的误差
希望求出全体数据的整体误差
那么可以对每项数据(u)的误差求和
这样就得到了全体数据的整体误差
```

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn32l11ak5j21760bajtr.jpg)

```bash
在公式前面加上1/2，以便简化后续计算
```

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn32pqnrrdj216m0bstc5.jpg)

```bash
此公式通常称为误差平方和
```

简称SSE计算方法就是对差值取平方再求和

还记得y^等于权重值和输入值的线性组合

再传入激活函数所得的结果

将其代入公式，可以看到误差取决于

权重值Wi和输入值Xi

全体数据用希腊字母u表示
可以将这些数据看成两组表格、数组、或者矩阵

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn3344b4t9j21ku0zytq7.jpg)

每项数据占一行位置u=1表示第一行数据
如果需要计算整体误差
可以逐行计算误差平方和
然后对所得结果求和
误差平方和，可用于衡量神经网络的预测效果
数值越高，预测效果越差
数值越底，预测效果越好
希望尽量降低误差平方和

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn338up0bej21m60zknk7.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn33bc9683j21ia0p6dr6.jpg)

在简单神经网络中，误差平方和等于目标值减去预测值(y-y^)取平方除以2的结果

在展开预测值之后，可以看出，权重是误差函数的参数

因此权重可被当做控制按钮，用来调整预测值，从而最终影响整体误差

目标是，求取能使误差最小化的权重值

这是单一权重误差函数的简化图像

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn33faoqhcj21300zsn5p.jpg)

目标是求取图形碗底对应的权值

从某个随机权值出发

逐步向误差最小值的方向前进

这个方向与梯度(斜率)相反

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn33iej3y9j21d80z0qfu.jpg)

只要始终沿着梯度，反复逐步下降

最终就能求得对应最小误差的权值

这就是梯度下降的过程

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn33m3u8boj21au10wqha.jpg)

下面来更新权值，新的权值Wi等于旧的Wi加上更新步长Wi
希腊大写字母通过表示变化量

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1fn33o5nwwuj20wq096wgm.jpg)

而梯度等于"误差关于每个权重Wi的偏导数"
公式中还需添加一个缩放系数变量用来控制梯度下降中更新步长的大小

这变量叫做学习速率，用希腊字母n表示
计算梯度需要使用到多元微积分