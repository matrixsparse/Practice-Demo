# 参数

## 参数共享

![All text](http://ww1.sinaimg.cn/large/dc05ba18ly1fnttge0k80j20m50dmtd3.jpg)

当我们试图识别一个猫的图片的时候，我们并不在意猫出现在哪个位置。无论是左上角，右下角，它在你眼里都是一只猫。我们希望 CNNs 能够无差别的识别，这如何做到呢？

如我们之前所见，一个给定的 patch 的分类，是由 patch 对应的权重和偏置项决定的。

如果我们想让左上角的猫与右下角的猫以同样的方式被识别，他们的权重和偏置项需要一样，这样他们才能以同一种方法识别。

这正是我们在 CNNs 中做的。一个给定输出层学到的权重和偏置项会共享在输入层所有的 patch 里。注意，当我们增大滤波器的深度的时候，我们需要学习的权重和偏置项的数量也会增加，因为权重并没有共享在所有输出的 channel 里。

共享参数还有一个额外的好处。如果我们不在所有的 patch 里用相同的权重，我们必须对每一个 patch 和它对应的隐藏层神经元学习新的参数。这不利于规模化，特别对于高清图片。因此，共享权重不仅帮我们平移不变，还给我们一个更小，可以规模化的模型

## Padding

![All text](http://ww1.sinaimg.cn/large/dc05ba18ly1fntth0wlkgj20cc090mx9.jpg)

假设现在有一个 5x5 网格 (如上图所示) 和一个尺寸为 3x3 stride值为 1 的滤波器(filter)。 下一层的 width 和 height 是多少呢？ 如图中所示，在水平和竖直方向都可以在3个不同的位置放置 patch， 下一层的维度即为 3x3 。下一层宽和高的尺寸就会按此规则缩放。

在理想状态下，我们可以在层间保持相同的宽度和高度，以便继续添加图层，保持网络的一致性，而不用担心维度的缩小。如何实现这一构想？其中一种简单的办法是，在 5x5 原始图片的外层包裹一圈 0 ，如下图所示

![All text](http://ww1.sinaimg.cn/large/dc05ba18ly1fntthh758fj20bg0ccaab.jpg)

这将会把原始图片扩展到 7x7。 现在我们知道如何让下一层图片的尺寸维持在 5x5，保持维度的一致性

## 维度

综合目前所学的知识，我们应该如何计算 CNN 中每一层神经元的数量呢？

输入层（input layer）维度值为W， 滤波器（filter）的维度值为 F (height * width * depth)， stride 的数值为 S， padding 的数值为 P， 下一层的维度值可用如下公式表示: (W−F+2P)/S+1。

我们可以通过每一层神经元的维度信息，得知模型的规模，并了解到我们设定的 filter size 和 stride 如何影响整个神经网络的尺寸。
