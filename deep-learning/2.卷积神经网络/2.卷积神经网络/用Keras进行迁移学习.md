# 用 Keras 进行迁移学习

我们将使用在ImageNet数据集上预先训练过的VGG-16模型，这个狗类数据集相对较小与ImageNet类别的子集有很高的重叠性

我们应该删掉网络的最后层级并添加一个新的分类层级，其中包含133个节点

然后仅训练该层级中的权重，并冻结其他层级中的所有权重，在Keras中可以通过多种方式实现这一目标，计算效率最高的是利用权重和预先训练的网络始终不会改变这一事实，我们可以将每个图片穿过该网络，并在最后的VGG-16最大池化层那停止，这样会将每个图片变成另一个三维数组，然后可以保存到新的数据集中

当我们编写网络时，我们将使用这个新数据集作为输入，我们在Keras中的网络将有两个层级，一个输入层和一个输出层

我们已经让每个图片穿过该网络，以便于为你节省一些时间，因此我们将此新数据集称为由瓶颈特征组成的数据集，我们需要创建一个传入7*7*512数组的模型

将其扁平化为向量并提供给剧透softMax的密集层，这就是这段代码的作用，我们还将总结该模型，我们看到该模型具有超过300万的参数，将需要很长的训练时间

这里我们不进行训练，但是如果你愿意的话，可以自己试试，我们将通过全局平均池化层降低维度
全局平均池化层简称GAP层，我们发现这样可以显著减少我们需要训练的参数数量，之前的模型具有超过300万个参数
但是这个模型的参数不到70000，接着编译该模型，当我们训练该模型时，它的运行速度极快，甚至在CPU上也很快，这是因为我们的模型只有两个层级，如果我们没有提前计算瓶颈特征，那么我们的训练流程速度会慢很多，因为我们需要在每个epoch中都让每个图片穿过深度神经网络，我们加载验证准确率最高的权重

```bash
# Load the weight that yielded the best validation accuracy
model.load_weights('dogvgg16.weights,best.hdf5')
```

当我们检查测试集的准确率时，发现结果大约是46%
似乎不太理想，但是随机猜测的准确率，只有大概1/133或不到1%的准确率
但你还可以在记事本中进一步优化，这些GAP层级的出现时间并不久
实际上，第一篇建议在CNN中使用GAP曾记得论文发表于几年前
甚至最近，在2016年MIT的研究人员演示指出经过分类任务训练并且具有GAP层级的CNN还可以用来进行对象定位
换句话说，这些CNN不仅能告诉我们图片中包含什么对象
而且可以告诉我们对象位于图片的哪个位置
如果你想尝试一些使用预先训练过的ResNet-50模型来定位对象和图片的代码
