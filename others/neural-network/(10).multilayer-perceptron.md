# multilayer perceptron

神经网络在多层感知器里面的数学部分需要具备以下知识：

* 向量
* 矩阵

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqaodjcbj20ne0dy0ul.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqb3wkn6j20jm07x3z0.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqmgujxlj20lv0e3dhx.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqmx5v3uj20ne036mxh.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqnm7dpgj20ks09kt9o.jpg)

上面的示意图，展示不同的权重在矩阵中与在神经网络中的对应关系

用 NumPy 来初始化这些权重，我们需要提供矩阵的形状（shape），如果特征是包一个包含以下数据的二维数组：

```bash
# Number of records and input units
# 数据点数量以及每个数据点有多少输入节点
n_records, n_inputs = features.shape
# Number of hidden units
# 隐藏层节点个数
n_hidden = 2
weights_input_to_hidden = np.random.normal(0, n_inputs**-0.5, size=(n_inputs, n_hidden))
```

这样创建了一个名为 weights_input_to_hidden 的二维数组，维度是 n_inputs 乘 n_hidden。记住，输入到隐藏节点是所有输入乘以隐藏节点权重的和。所以对每一个隐藏层节点 h
​j，我们需要计算：

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqy35j7fj20gc02yt8m.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqyxbfgej20no03fmxr.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqzgxllpj20kj0edgmh.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqzzaqytj20gz023747.jpg)

针对第二个隐藏节点的输入，你需要计算输入与第二列的点积，以此类推。

在 NumPy 中，你可以直接使用 np.dot

```bash
hidden_inputs = np.dot(inputs, weights_input_to_hidden)
```

你可以定义你的权重矩阵的维度是 n_hidden 乘 n_inputs 然后与列向量形式的输入相乘：

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwr1vop78j20jr05j748.jpg)

>注意

```bash
这里权重的索引在上图中做了改变，与之前图片并不匹配

这是因为，在矩阵标注时行索引永远在列索引之前，所以用之前的方法做标识会引起误导

你只需要了解这跟之前的权重矩阵是一样的

只是做了转换，之前的第一列现在是第一行，之前的第二列现在是第二行

如果用之前的标记，权重矩阵是下面这个样子的
```

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwr7hh8qmj20jx055mx3.jpg)

切记，上面标注方式是不正确的，这里只是为了让你更清楚这个矩阵如何跟之前神经网络的权重匹配

矩阵相乘最重要的是他们的维度相匹配

因为它们在点乘时需要有相同数量的元素

在第一个例子中，输入向量有三列，权重矩阵有三行；第二个例子中，权重矩阵有三列，输入向量有三行

如果维度不匹配，你会得到：

```bash
# Same weights and features as above, but swapped the order
hidden_inputs = np.dot(weights_input_to_hidden, features)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-11-1bfa0f615c45> in <module>()
----> 1 hidden_in = np.dot(weights_input_to_hidden, X)

ValueError: shapes (3,2) and (3,) not aligned: 2 (dim 1) != 3 (dim 0)
```

3x2 的矩阵跟 3 个元素的数组是没法相乘的

因为矩阵中的两列与数组中的元素个数并不匹配

能够相乘的矩阵如下：


![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwra2jh2ej20o1068aai.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwra2j71ej20iq04ydfx.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwra2k3n7j20mr07maao.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwra2jpucj20m2043aa5.jpg)

## 构建一个列向量

看上面的介绍，你有时会需要一个列向量，尽管 NumPy 默认是行向量。你可以用 arr.T 来对数组进行转置，但对一维数组来说，转置还是行向量。所以你可以用 arr[:,None] 来创建一个列向量：

```bash
print(features)
> array([ 0.49671415, -0.1382643 ,  0.64768854])

print(features.T)
> array([ 0.49671415, -0.1382643 ,  0.64768854])

print(features[:, None])
> array([[ 0.49671415],
       [-0.1382643 ],
       [ 0.64768854]])
```

当然，你可以创建一个二维数组，然后用 arr.T 得到列向量

```bash
np.array(features, ndmin=2)
> array([[ 0.49671415, -0.1382643 ,  0.64768854]])

np.array(features, ndmin=2).T
> array([[ 0.49671415],
       [-0.1382643 ],
       [ 0.64768854]])
```

我个人更倾向于保持所有向量为一维数组，这样可以更好认知

>demo

下面你要实现一个 4x3x2 网络的正向传播，用 sigmoid 作为两层的激活函数。

要做的事情：

* 计算隐藏层的输入
* 计算隐藏层输出
* 计算输出层的输入
* 计算神经网络的输出