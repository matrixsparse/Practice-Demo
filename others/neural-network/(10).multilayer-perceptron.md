# multilayer perceptron

神经网络在多层感知器里面的数学部分需要具备以下知识：

* 向量
* 矩阵

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqaodjcbj20ne0dy0ul.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqb3wkn6j20jm07x3z0.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqmgujxlj20lv0e3dhx.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqmx5v3uj20ne036mxh.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqnm7dpgj20ks09kt9o.jpg)

上面的示意图，展示不同的权重在矩阵中与在神经网络中的对应关系

用 NumPy 来初始化这些权重，我们需要提供矩阵的形状（shape），如果特征是包一个包含以下数据的二维数组：

```bash
# Number of records and input units
# 数据点数量以及每个数据点有多少输入节点
n_records, n_inputs = features.shape
# Number of hidden units
# 隐藏层节点个数
n_hidden = 2
weights_input_to_hidden = np.random.normal(0, n_inputs**-0.5, size=(n_inputs, n_hidden))
```

这样创建了一个名为 weights_input_to_hidden 的二维数组，维度是 n_inputs 乘 n_hidden。记住，输入到隐藏节点是所有输入乘以隐藏节点权重的和。所以对每一个隐藏层节点 h
​j，我们需要计算：

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqy35j7fj20gc02yt8m.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqyxbfgej20no03fmxr.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqzgxllpj20kj0edgmh.jpg)

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwqzzaqytj20gz023747.jpg)

针对第二个隐藏节点的输入，你需要计算输入与第二列的点积，以此类推。

在 NumPy 中，你可以直接使用 np.dot

```bash
hidden_inputs = np.dot(inputs, weights_input_to_hidden)
```

你可以定义你的权重矩阵的维度是 n_hidden 乘 n_inputs 然后与列向量形式的输入相乘：

![All text](http://ww1.sinaimg.cn/large/dc05ba18gy1flwr1vop78j20jr05j748.jpg)